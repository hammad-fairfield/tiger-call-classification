{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acb475f-6407-4775-8c84-3a1f12f5ca55",
   "metadata": {
    "id": "0acb475f-6407-4775-8c84-3a1f12f5ca55"
   },
   "outputs": [],
   "source": [
    "!pip uninstall -y tensorflow-gpu\n",
    "!pip uninstall -y tensorflow-io\n",
    "!pip install tensorflow-gpu\n",
    "!pip install --no-deps tensorflow-io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266fdc21-1415-4fdb-a9a4-2727cdd16c9d",
   "metadata": {
    "id": "266fdc21-1415-4fdb-a9a4-2727cdd16c9d"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from itertools import groupby\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import tensorflow as tf \n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, Dense, Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jlHd9lO5pmzV",
   "metadata": {
    "id": "jlHd9lO5pmzV"
   },
   "outputs": [],
   "source": [
    "#Mounting Google Drive to a Colab instance. Only to be executed if running on Colab.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a03bd8-8750-4cb5-a633-249a6cd87888",
   "metadata": {
    "id": "a4a03bd8-8750-4cb5-a633-249a6cd87888"
   },
   "outputs": [],
   "source": [
    "#This function loads an audio clip and resamples it to 16000 samples/second\n",
    "\n",
    "def load_wav_16k_mono(filename):\n",
    "    # Load encoded wav file\n",
    "    file_contents = tf.io.read_file(filename)\n",
    "    # Decode wav (tensors by channels) \n",
    "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
    "    # Removes trailing axis\n",
    "    wav = tf.squeeze(wav, axis=-1)\n",
    "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
    "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
    "    wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
    "    return wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddbc067-3810-4ccf-acde-72d4b84277cc",
   "metadata": {
    "id": "eddbc067-3810-4ccf-acde-72d4b84277cc"
   },
   "outputs": [],
   "source": [
    "#Storing samples from each class for test runs\n",
    "TIGER_FILE = \"/content/drive/MyDrive/dataset/TIGER/SMM01167_20220929_155802_1146_reduced_16BIT.wav\"\n",
    "NOT_TIGER_FILE = \"/content/drive/MyDrive/dataset/NO_TIGER/SMM01167_20220929_155802_5_reduced_16BIT.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50520b3-7a4c-413d-b2f2-85677b4a6a22",
   "metadata": {
    "id": "f50520b3-7a4c-413d-b2f2-85677b4a6a22"
   },
   "outputs": [],
   "source": [
    "#Loading test files and assigning them to variables\n",
    "wave = load_wav_16k_mono(TIGER_FILE)\n",
    "nwave = load_wav_16k_mono(NOT_TIGER_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58793afc-27a3-4550-a5b4-29eced2016b4",
   "metadata": {
    "id": "58793afc-27a3-4550-a5b4-29eced2016b4"
   },
   "outputs": [],
   "source": [
    "#Plotting example positive and negative samples\n",
    "plt.plot(wave)\n",
    "plt.plot(nwave)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030316a0-d016-4772-baa4-b712156a8d85",
   "metadata": {
    "id": "030316a0-d016-4772-baa4-b712156a8d85"
   },
   "outputs": [],
   "source": [
    "#This creates a dataset from the positive and negative samples and loads them onto two variables\n",
    "pos = tf.data.Dataset.list_files('/content/drive/MyDrive/dataset/TIGER/*.wav')\n",
    "neg = tf.data.Dataset.list_files('/content/drive/MyDrive/dataset/NO_TIGER/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df36e67a-7c59-461d-886e-ad6a3baa6ef4",
   "metadata": {
    "id": "df36e67a-7c59-461d-886e-ad6a3baa6ef4"
   },
   "outputs": [],
   "source": [
    "#Adding samples labels to each sample set. potsitive examples are assigned label '1' and negative samples are assigned label '0'\n",
    "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
    "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n",
    "#Consolidating all samples under one variable sequentially\n",
    "data = positives.concatenate(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eeee0f2-245e-428d-a7da-9c237b7e311c",
   "metadata": {
    "id": "1eeee0f2-245e-428d-a7da-9c237b7e311c"
   },
   "outputs": [],
   "source": [
    "#This function loads an audio clip and converts it to a spectrogram for further processing\n",
    "\n",
    "def preprocess(file_path, label): \n",
    "    wav = load_wav_16k_mono(file_path)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=320, window_fn=None)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53261dfb",
   "metadata": {
    "id": "53261dfb"
   },
   "outputs": [],
   "source": [
    "#Extracting one sample and plotting it's spectrogram for analysis\n",
    "\n",
    "filepath, label = positives.shuffle(buffer_size=10000).as_numpy_iterator().next()\n",
    "spectrogram, label = preprocess(filepath, label)\n",
    "\n",
    "plt.figure(figsize=(7,4))\n",
    "plt.imshow(tf.transpose(spectrogram)[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd2a8b3-220e-4f2d-97ed-f04310068fc3",
   "metadata": {
    "id": "8dd2a8b3-220e-4f2d-97ed-f04310068fc3"
   },
   "outputs": [],
   "source": [
    "#Creating a data loading pipeline, that shuffles the dataset and creates batches of 16 images\n",
    "\n",
    "data = data.map(preprocess)\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1000)\n",
    "data = data.batch(16)\n",
    "data = data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1442df8f",
   "metadata": {
    "id": "1442df8f"
   },
   "outputs": [],
   "source": [
    "#Splitting dataset into train and test sets\n",
    "train = data.take(12)\n",
    "test = data.skip(12).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3306bc6",
   "metadata": {
    "id": "c3306bc6"
   },
   "outputs": [],
   "source": [
    "#Extracting random example from train set\n",
    "samples, labels = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203adefb",
   "metadata": {
    "id": "203adefb"
   },
   "outputs": [],
   "source": [
    "#Outputs shape of example train sample. \n",
    "#This gives the input_shape for the Convolutional Neural Network\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0b71e5-f5d6-40cb-9643-f2136117dacd",
   "metadata": {
    "id": "9f0b71e5-f5d6-40cb-9643-f2136117dacd"
   },
   "outputs": [],
   "source": [
    "#Creating a sequential convolutional neural network model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), activation='relu', input_shape=(150,257,1)))\n",
    "model.add(Conv2D(16, (3,3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44efbe9e-8137-4937-bebb-8a6d2515f800",
   "metadata": {
    "id": "44efbe9e-8137-4937-bebb-8a6d2515f800"
   },
   "outputs": [],
   "source": [
    "#Model compilation\n",
    "model.compile('Adam', loss='BinaryCrossentropy', metrics=[tf.keras.metrics.Recall(),tf.keras.metrics.Precision()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f592e27-1c74-43b0-aca2-35b32e8fdba7",
   "metadata": {
    "id": "2f592e27-1c74-43b0-aca2-35b32e8fdba7"
   },
   "outputs": [],
   "source": [
    "#Outputs model summary and model parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7919b0-20dd-4503-87f5-e2fc7d33b1ef",
   "metadata": {
    "id": "2b7919b0-20dd-4503-87f5-e2fc7d33b1ef"
   },
   "outputs": [],
   "source": [
    "#Initiating training instance and storing results in 'hist' variable\n",
    "hist = model.fit(train, epochs=3, validation_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17940230-a190-4961-8b70-bf0ea5f2d123",
   "metadata": {
    "id": "17940230-a190-4961-8b70-bf0ea5f2d123"
   },
   "outputs": [],
   "source": [
    "#Plotting Loss\n",
    "plt.title('Loss')\n",
    "plt.plot(hist.history['loss'], 'r')\n",
    "plt.plot(hist.history['val_loss'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b879993-e727-484a-8cc5-101df9264440",
   "metadata": {
    "id": "1b879993-e727-484a-8cc5-101df9264440"
   },
   "outputs": [],
   "source": [
    "#Plotting Precision\n",
    "plt.title('Precision')\n",
    "plt.plot(hist.history['precision'], 'r')\n",
    "plt.plot(hist.history['val_precision'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb904b0-9c02-4be5-84f4-277584158746",
   "metadata": {
    "id": "5eb904b0-9c02-4be5-84f4-277584158746"
   },
   "outputs": [],
   "source": [
    "#Plotting Recall\n",
    "plt.title('Recall')\n",
    "plt.plot(hist.history['recall'], 'r')\n",
    "plt.plot(hist.history['val_recall'], 'b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37fc1cf-23ca-44fa-a0fc-75f9986c3dbe",
   "metadata": {
    "id": "a37fc1cf-23ca-44fa-a0fc-75f9986c3dbe"
   },
   "outputs": [],
   "source": [
    "#Extracting an example from the test set to check model performance\n",
    "X_test, y_test = test.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192ed7b3-ef0d-4319-8aff-135b716631f6",
   "metadata": {
    "id": "192ed7b3-ef0d-4319-8aff-135b716631f6"
   },
   "outputs": [],
   "source": [
    "#Testing model by making prediction from extracted test sample\n",
    "yhat = model.predict(X_test)\n",
    "yhat = [1 if prediction > 0.5 else 0 for prediction in yhat]\n",
    "print(yhat)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e017c-99ef-41d8-826b-62d231851524",
   "metadata": {
    "id": "312e017c-99ef-41d8-826b-62d231851524"
   },
   "outputs": [],
   "source": [
    "#Testing functions that will be used to ensure correctness\n",
    "RECORDING = os.path.join('dataset','RECORDING','SOUND_16BIT.wav')\n",
    "test_wav = load_wav_16k_mono(RECORDING)\n",
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(test_wav, test_wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
    "samples, index = audio_slices.as_numpy_iterator().next()\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60ee2c0-37a2-4f5b-8084-1713ba9ac938",
   "metadata": {
    "id": "f60ee2c0-37a2-4f5b-8084-1713ba9ac938"
   },
   "outputs": [],
   "source": [
    "#This function performs required preprocessing for test dataset\n",
    "def preprocess_dataset(sample, index):\n",
    "    sample = sample[0]\n",
    "    zero_padding = tf.zeros([48000] - tf.shape(sample), dtype=tf.float32)\n",
    "    wav = tf.concat([zero_padding, sample],0)\n",
    "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=320)\n",
    "    spectrogram = tf.abs(spectrogram)\n",
    "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
    "    return spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a9750-f1fa-4bda-8530-e84b89fb9438",
   "metadata": {
    "id": "337a9750-f1fa-4bda-8530-e84b89fb9438"
   },
   "outputs": [],
   "source": [
    "#Splitting extracted sample into 3 second clips\n",
    "audio_slices = tf.keras.utils.timeseries_dataset_from_array(test_wav, test_wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
    "#Mapping preprocessing function to extracted sample\n",
    "audio_slices = audio_slices.map(preprocess_dataset)\n",
    "#Creating batches of 64\n",
    "audio_slices = audio_slices.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ee368-84a7-4d81-981d-12e662908f2a",
   "metadata": {
    "id": "592ee368-84a7-4d81-981d-12e662908f2a"
   },
   "outputs": [],
   "source": [
    "#Performing predictions on the extracted sample to and creating class prediction array\n",
    "yhat = model.predict(audio_slices)\n",
    "yhat = [1 if prediction > 0.99 else 0 for prediction in yhat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5c6f42-221d-4c6e-aba5-4887de65f5ac",
   "metadata": {
    "id": "bc5c6f42-221d-4c6e-aba5-4887de65f5ac"
   },
   "outputs": [],
   "source": [
    "#Grouping class predictions and storing call density in 'calls' variable\n",
    "yhat = [key for key, group in groupby(yhat)]\n",
    "calls = tf.math.reduce_sum(yhat).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cde051-4d84-4c5a-b8a4-86bc1a47c5bb",
   "metadata": {
    "id": "e2cde051-4d84-4c5a-b8a4-86bc1a47c5bb"
   },
   "outputs": [],
   "source": [
    "#This code window performs the prediction on a set of audio files and stores them into an array against the name of the file\n",
    "\n",
    "results = {}\n",
    "for file in os.listdir('/content/drive/MyDrive/dataset/RECORDING'):\n",
    "    FILEPATH = os.path.join('/content/drive/MyDrive/dataset/RECORDING', file)\n",
    "    \n",
    "    wav = load_wav_16k_mono(FILEPATH)\n",
    "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(wav, wav, sequence_length=48000, sequence_stride=48000, batch_size=1)\n",
    "    audio_slices = audio_slices.map(preprocess_new)\n",
    "    audio_slices = audio_slices.batch(16)\n",
    "    \n",
    "    yhat = model.predict(audio_slices)\n",
    "    \n",
    "    results[file] = yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f336d2b1-7e40-4bdc-8cab-3d654d7a430b",
   "metadata": {
    "id": "f336d2b1-7e40-4bdc-8cab-3d654d7a430b"
   },
   "outputs": [],
   "source": [
    "for key in results.keys():\n",
    "  print(len(results[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41797d2-2064-4874-82ca-7ba56f04883f",
   "metadata": {
    "id": "f41797d2-2064-4874-82ca-7ba56f04883f"
   },
   "outputs": [],
   "source": [
    "#Converts predictions stored in the results file to class predictions\n",
    "class_preds = {}\n",
    "for file, logits in results.items():\n",
    "    class_preds[file] = [1 if prediction > 0.99 else 0 for prediction in logits]\n",
    "#class_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g5shaihRiDhY",
   "metadata": {
    "id": "g5shaihRiDhY"
   },
   "outputs": [],
   "source": [
    "class_preds.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b04c19",
   "metadata": {
    "id": "47b04c19"
   },
   "outputs": [],
   "source": [
    "#Functions to facilitate creating a csv file and storing time stepped results\n",
    "def convert(n):\n",
    "    return str(datetime.timedelta(seconds = n))\n",
    "\n",
    "def save_results(directory, dictionary):    \n",
    "    try:\n",
    "        os.mkdir(directory)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    for file, logits in class_preds.items():\n",
    "      col_len = len(logits)\n",
    "      sec = [x for x in range(0, col_len*3, 3)]\n",
    "      form = [convert(x) for x in sec]\n",
    "\n",
    "      df = pd.DataFrame({'Timestep': form, 'Prediction': logits}).set_index('Timestep')\n",
    "      path = directory + '/'+ file[0:-4] + '_output.xlsx'\n",
    "      df.to_excel(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1044d412",
   "metadata": {
    "id": "1044d412"
   },
   "outputs": [],
   "source": [
    "save_results('/content/drive/MyDrive/TIMED_RESULTS', class_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c15cbfe-b27c-4d0b-af31-2c4991fccb36",
   "metadata": {
    "id": "8c15cbfe-b27c-4d0b-af31-2c4991fccb36"
   },
   "outputs": [],
   "source": [
    "#This code window, groups consecutive prediction into a single value and outputs sum of all positive samples.\n",
    "#This gives us the call density for each file\n",
    "postprocessed = {}\n",
    "for file, scores in class_preds.items():\n",
    "    postprocessed[file] = tf.math.reduce_sum([key for key, group in groupby(scores)]).numpy()\n",
    "#postprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b86f21-9755-4d75-832a-a9e730216c40",
   "metadata": {
    "id": "86b86f21-9755-4d75-832a-a9e730216c40"
   },
   "outputs": [],
   "source": [
    "#Stores call density into a csv file for further study\n",
    "with open('/content/drive/MyDrive/results.csv', 'w', newline='') as f:\n",
    "    writer = csv.writer(f, delimiter=',')\n",
    "    writer.writerow(['Recording', 'Main Calls'])\n",
    "    for key, value in postprocessed.items():\n",
    "        writer.writerow([key, value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2287f9d-ed49-4196-912c-3df1ce14a77f",
   "metadata": {
    "id": "f2287f9d-ed49-4196-912c-3df1ce14a77f"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
